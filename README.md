# **Local Chat App with Streamlit, Langchain, and Ollama**
This repository contains the code and documentation for a local chat application using Streamlit, Langchain, and Ollama. The application allows users to chat with an AI model locally on their machine.



## **Prerequisites**
Before running the application, ensure that you have the following installed on your machine:
* Python 3.7 or higher
* pip (Python package installer)
* Download and Run Ollama (the application)



_Virtual Env recommended but not required_



## **Install all required packages:**

```pip install streamlit langchain langchain-community ollama chromadb```




## **To run the local LLM, run the following command in your terminal of choice:**

```streamlit run ~/Downloads/local_llama3.1.py (or wherever you cloned the file)```




## **Contact Information**
For any questions or issues, please contact Sanjay Amirthraj.


### Once running, your page should look something like this:
Have fun!

![Screenshot 2024-07-24 at 5 05 05â€¯PM](https://github.com/user-attachments/assets/62c81d6a-74d7-4c6b-a651-de25a2c6f1f9)
