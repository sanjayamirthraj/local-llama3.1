# **Local Chat App with Streamlit, Langchain, and Ollama**
This repository contains the code and documentation for a local chat application using Streamlit, Langchain, and Ollama. The application allows users to chat with an AI model locally on their machine.



## **Prerequisites**
Before running the application, ensure that you have the following installed on your machine:
* Python 3.7 or higher
* pip (Python package installer)



_Virtual Env recommended but not required_



## **Install all required packages:**

```pip install streamlit langchain langchain-community ollama chromadb```




## **To run the local LLM, run the following command in your terminal of choice:**

```streamlit run ~/Downloads/local_llama3.1.py or where ever you cloned the file```




## **Contact Information**
For any questions or issues, please contact Sanjay Amirthraj.

### Once running, your page should look something like this:
Have fun!
![Screenshot 2024-07-24 at 4 45 46â€¯PM](https://github.com/user-attachments/assets/09b6ff3d-0393-4fa4-9bf6-1135f079795b)

